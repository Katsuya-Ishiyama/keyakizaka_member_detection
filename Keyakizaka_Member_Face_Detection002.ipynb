{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNetV2で欅坂46とけやき坂46のメンバーの顔認識"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ishiyama/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications.mobilenetv2 import MobileNetV2\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.utils import load_data\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルと学習の設定\n",
    "EPOCHを200に設定した理由は、ある程度大きい数値、かつ、1エポックあたり60秒なので全体で2.2時間とトライ・アンド・エラーしやすかったため。  \n",
    "テストとバリデーションのデータサイズはともに0.1（＝全体の10%）を指定した。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの設定\n",
    "NUMBER_OF_MEMBERS = 41             # 漢字とひらがな合わせたメンバー数\n",
    "CLASSES = NUMBER_OF_MEMBERS + 1    # one hot表現は0から始まるため\n",
    "LOG_DIR = './logs'                 # LossとAccuracyのログ\n",
    "\n",
    "# 学習の設定\n",
    "EPOCHS = 200\n",
    "TEST_SIZE = 0.1\n",
    "VALIDATION_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = load_data('/home/ishiyama/notebooks/keyakizaka_member_detection/image/mobilenet/')\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=TEST_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetV2(include_top=True, weights=None, classes=CLASSES)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "callbacks = keras.callbacks.TensorBoard(log_dir=LOG_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習させる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10347 samples, validate on 1150 samples\n",
      "Epoch 1/200\n",
      " - 67s - loss: 3.5876 - acc: 0.0833 - val_loss: 11.7200 - val_acc: 0.0296\n",
      "Epoch 2/200\n",
      " - 63s - loss: 3.0783 - acc: 0.1872 - val_loss: 13.8211 - val_acc: 0.0400\n",
      "Epoch 3/200\n",
      " - 63s - loss: 2.6830 - acc: 0.2734 - val_loss: 13.0619 - val_acc: 0.0304\n",
      "Epoch 4/200\n",
      " - 64s - loss: 2.2993 - acc: 0.3758 - val_loss: 14.2935 - val_acc: 0.0426\n",
      "Epoch 5/200\n",
      " - 64s - loss: 1.9333 - acc: 0.4670 - val_loss: 13.2981 - val_acc: 0.0652\n",
      "Epoch 6/200\n",
      " - 64s - loss: 1.6151 - acc: 0.5505 - val_loss: 12.8824 - val_acc: 0.0696\n",
      "Epoch 7/200\n",
      " - 64s - loss: 1.3459 - acc: 0.6257 - val_loss: 13.5503 - val_acc: 0.0583\n",
      "Epoch 8/200\n",
      " - 64s - loss: 1.1108 - acc: 0.6897 - val_loss: 11.7506 - val_acc: 0.1096\n",
      "Epoch 9/200\n",
      " - 64s - loss: 0.9212 - acc: 0.7380 - val_loss: 13.7192 - val_acc: 0.0661\n",
      "Epoch 10/200\n",
      " - 64s - loss: 0.7483 - acc: 0.7878 - val_loss: 14.7393 - val_acc: 0.0357\n",
      "Epoch 11/200\n",
      " - 64s - loss: 0.6472 - acc: 0.8136 - val_loss: 11.1138 - val_acc: 0.1365\n",
      "Epoch 12/200\n",
      " - 64s - loss: 0.5088 - acc: 0.8536 - val_loss: 13.2723 - val_acc: 0.0557\n",
      "Epoch 13/200\n",
      " - 64s - loss: 0.4421 - acc: 0.8666 - val_loss: 14.0807 - val_acc: 0.0409\n",
      "Epoch 14/200\n",
      " - 64s - loss: 0.3876 - acc: 0.8825 - val_loss: 12.9501 - val_acc: 0.0678\n",
      "Epoch 15/200\n",
      " - 65s - loss: 0.3503 - acc: 0.8954 - val_loss: 9.9021 - val_acc: 0.1878\n",
      "Epoch 16/200\n",
      " - 65s - loss: 0.3212 - acc: 0.9038 - val_loss: 12.9530 - val_acc: 0.0843\n",
      "Epoch 17/200\n",
      " - 65s - loss: 0.2597 - acc: 0.9243 - val_loss: 8.6502 - val_acc: 0.2052\n",
      "Epoch 18/200\n",
      " - 64s - loss: 0.2837 - acc: 0.9144 - val_loss: 10.2227 - val_acc: 0.1504\n",
      "Epoch 19/200\n",
      " - 64s - loss: 0.2413 - acc: 0.9268 - val_loss: 10.0536 - val_acc: 0.1548\n",
      "Epoch 20/200\n",
      " - 65s - loss: 0.2525 - acc: 0.9262 - val_loss: 11.3201 - val_acc: 0.1400\n",
      "Epoch 21/200\n",
      " - 65s - loss: 0.2365 - acc: 0.9324 - val_loss: 8.0956 - val_acc: 0.2522\n",
      "Epoch 22/200\n",
      " - 65s - loss: 0.2534 - acc: 0.9214 - val_loss: 10.5794 - val_acc: 0.1704\n",
      "Epoch 23/200\n",
      " - 65s - loss: 0.2052 - acc: 0.9413 - val_loss: 6.3243 - val_acc: 0.3357\n",
      "Epoch 24/200\n",
      " - 65s - loss: 0.2111 - acc: 0.9401 - val_loss: 7.8812 - val_acc: 0.2626\n",
      "Epoch 25/200\n",
      " - 65s - loss: 0.1887 - acc: 0.9442 - val_loss: 8.7863 - val_acc: 0.2070\n",
      "Epoch 26/200\n",
      " - 64s - loss: 0.1787 - acc: 0.9482 - val_loss: 6.1454 - val_acc: 0.3809\n",
      "Epoch 27/200\n",
      " - 65s - loss: 0.2039 - acc: 0.9438 - val_loss: 9.8730 - val_acc: 0.1896\n",
      "Epoch 28/200\n",
      " - 64s - loss: 0.1877 - acc: 0.9465 - val_loss: 7.2931 - val_acc: 0.3000\n",
      "Epoch 29/200\n",
      " - 64s - loss: 0.1729 - acc: 0.9514 - val_loss: 9.0967 - val_acc: 0.2200\n",
      "Epoch 30/200\n",
      " - 64s - loss: 0.1374 - acc: 0.9641 - val_loss: 4.4003 - val_acc: 0.4730\n",
      "Epoch 31/200\n",
      " - 64s - loss: 0.1507 - acc: 0.9592 - val_loss: 7.0095 - val_acc: 0.2939\n",
      "Epoch 32/200\n",
      " - 65s - loss: 0.1884 - acc: 0.9506 - val_loss: 7.5875 - val_acc: 0.2965\n",
      "Epoch 33/200\n",
      " - 64s - loss: 0.1868 - acc: 0.9439 - val_loss: 8.7197 - val_acc: 0.2322\n",
      "Epoch 34/200\n",
      " - 64s - loss: 0.1630 - acc: 0.9570 - val_loss: 4.6238 - val_acc: 0.4504\n",
      "Epoch 35/200\n",
      " - 64s - loss: 0.1481 - acc: 0.9607 - val_loss: 6.4571 - val_acc: 0.3322\n",
      "Epoch 36/200\n",
      " - 65s - loss: 0.1363 - acc: 0.9655 - val_loss: 6.2867 - val_acc: 0.3496\n",
      "Epoch 37/200\n",
      " - 65s - loss: 0.1158 - acc: 0.9685 - val_loss: 4.2952 - val_acc: 0.4852\n",
      "Epoch 38/200\n",
      " - 64s - loss: 0.1580 - acc: 0.9553 - val_loss: 7.0496 - val_acc: 0.3452\n",
      "Epoch 39/200\n",
      " - 65s - loss: 0.1489 - acc: 0.9625 - val_loss: 7.9126 - val_acc: 0.2791\n",
      "Epoch 40/200\n",
      " - 65s - loss: 0.1332 - acc: 0.9638 - val_loss: 9.1660 - val_acc: 0.2217\n",
      "Epoch 41/200\n",
      " - 64s - loss: 0.1579 - acc: 0.9537 - val_loss: 5.8402 - val_acc: 0.3670\n",
      "Epoch 42/200\n",
      " - 64s - loss: 0.1346 - acc: 0.9611 - val_loss: 4.8482 - val_acc: 0.4191\n",
      "Epoch 43/200\n",
      " - 65s - loss: 0.1262 - acc: 0.9652 - val_loss: 4.6207 - val_acc: 0.4565\n",
      "Epoch 44/200\n",
      " - 65s - loss: 0.1072 - acc: 0.9710 - val_loss: 4.3994 - val_acc: 0.4948\n",
      "Epoch 45/200\n",
      " - 65s - loss: 0.0952 - acc: 0.9745 - val_loss: 4.7048 - val_acc: 0.4739\n",
      "Epoch 46/200\n",
      " - 65s - loss: 0.1125 - acc: 0.9692 - val_loss: 7.2864 - val_acc: 0.2904\n",
      "Epoch 47/200\n",
      " - 64s - loss: 0.1362 - acc: 0.9615 - val_loss: 5.8797 - val_acc: 0.3922\n",
      "Epoch 48/200\n",
      " - 65s - loss: 0.1127 - acc: 0.9701 - val_loss: 7.3646 - val_acc: 0.3017\n",
      "Epoch 49/200\n",
      " - 65s - loss: 0.1109 - acc: 0.9692 - val_loss: 5.7613 - val_acc: 0.3904\n",
      "Epoch 50/200\n",
      " - 65s - loss: 0.1198 - acc: 0.9669 - val_loss: 8.4621 - val_acc: 0.2435\n",
      "Epoch 51/200\n",
      " - 65s - loss: 0.1087 - acc: 0.9699 - val_loss: 7.4904 - val_acc: 0.3052\n",
      "Epoch 52/200\n",
      " - 65s - loss: 0.1104 - acc: 0.9684 - val_loss: 4.1742 - val_acc: 0.4939\n",
      "Epoch 53/200\n",
      " - 65s - loss: 0.1280 - acc: 0.9616 - val_loss: 5.9031 - val_acc: 0.4078\n",
      "Epoch 54/200\n",
      " - 65s - loss: 0.0914 - acc: 0.9747 - val_loss: 4.6238 - val_acc: 0.4557\n",
      "Epoch 55/200\n",
      " - 65s - loss: 0.0987 - acc: 0.9718 - val_loss: 5.6505 - val_acc: 0.3643\n",
      "Epoch 56/200\n",
      " - 65s - loss: 0.0887 - acc: 0.9753 - val_loss: 3.3857 - val_acc: 0.5504\n",
      "Epoch 57/200\n",
      " - 65s - loss: 0.0940 - acc: 0.9743 - val_loss: 3.5529 - val_acc: 0.5313\n",
      "Epoch 58/200\n",
      " - 65s - loss: 0.0717 - acc: 0.9818 - val_loss: 3.7454 - val_acc: 0.5478\n",
      "Epoch 59/200\n",
      " - 65s - loss: 0.0694 - acc: 0.9817 - val_loss: 3.9099 - val_acc: 0.5548\n",
      "Epoch 60/200\n",
      " - 65s - loss: 0.0800 - acc: 0.9792 - val_loss: 4.5404 - val_acc: 0.5026\n",
      "Epoch 61/200\n",
      " - 65s - loss: 0.1106 - acc: 0.9686 - val_loss: 4.6232 - val_acc: 0.4896\n",
      "Epoch 62/200\n",
      " - 65s - loss: 0.1179 - acc: 0.9637 - val_loss: 6.0308 - val_acc: 0.4035\n",
      "Epoch 63/200\n",
      " - 65s - loss: 0.1042 - acc: 0.9698 - val_loss: 5.4840 - val_acc: 0.4496\n",
      "Epoch 64/200\n",
      " - 65s - loss: 0.0601 - acc: 0.9825 - val_loss: 3.1827 - val_acc: 0.5765\n",
      "Epoch 65/200\n",
      " - 65s - loss: 0.0791 - acc: 0.9766 - val_loss: 4.7898 - val_acc: 0.4835\n",
      "Epoch 66/200\n",
      " - 65s - loss: 0.0952 - acc: 0.9712 - val_loss: 3.7096 - val_acc: 0.5357\n",
      "Epoch 67/200\n",
      " - 65s - loss: 0.0995 - acc: 0.9724 - val_loss: 3.5146 - val_acc: 0.5487\n",
      "Epoch 68/200\n",
      " - 65s - loss: 0.0632 - acc: 0.9834 - val_loss: 4.5984 - val_acc: 0.4852\n",
      "Epoch 69/200\n",
      " - 64s - loss: 0.0497 - acc: 0.9857 - val_loss: 3.5769 - val_acc: 0.5530\n",
      "Epoch 70/200\n",
      " - 65s - loss: 0.0567 - acc: 0.9839 - val_loss: 3.5869 - val_acc: 0.5443\n",
      "Epoch 71/200\n",
      " - 65s - loss: 0.0892 - acc: 0.9716 - val_loss: 4.3318 - val_acc: 0.4574\n",
      "Epoch 72/200\n",
      " - 65s - loss: 0.0910 - acc: 0.9737 - val_loss: 6.0939 - val_acc: 0.3470\n",
      "Epoch 73/200\n",
      " - 65s - loss: 0.0804 - acc: 0.9767 - val_loss: 3.5523 - val_acc: 0.5826\n",
      "Epoch 74/200\n",
      " - 65s - loss: 0.0902 - acc: 0.9713 - val_loss: 4.3671 - val_acc: 0.4887\n",
      "Epoch 75/200\n",
      " - 65s - loss: 0.0519 - acc: 0.9848 - val_loss: 3.7643 - val_acc: 0.5470\n",
      "Epoch 76/200\n",
      " - 65s - loss: 0.0434 - acc: 0.9881 - val_loss: 3.4199 - val_acc: 0.5774\n",
      "Epoch 77/200\n",
      " - 65s - loss: 0.0620 - acc: 0.9811 - val_loss: 4.2067 - val_acc: 0.5113\n",
      "Epoch 78/200\n",
      " - 65s - loss: 0.0857 - acc: 0.9722 - val_loss: 4.1973 - val_acc: 0.4765\n",
      "Epoch 79/200\n",
      " - 65s - loss: 0.0790 - acc: 0.9763 - val_loss: 5.5916 - val_acc: 0.4096\n",
      "Epoch 80/200\n",
      " - 65s - loss: 0.0697 - acc: 0.9792 - val_loss: 3.7635 - val_acc: 0.5757\n",
      "Epoch 81/200\n",
      " - 65s - loss: 0.0628 - acc: 0.9813 - val_loss: 3.8677 - val_acc: 0.5017\n",
      "Epoch 82/200\n",
      " - 65s - loss: 0.0438 - acc: 0.9862 - val_loss: 4.3656 - val_acc: 0.5296\n",
      "Epoch 83/200\n",
      " - 65s - loss: 0.0562 - acc: 0.9821 - val_loss: 3.5856 - val_acc: 0.5478\n",
      "Epoch 84/200\n",
      " - 65s - loss: 0.0578 - acc: 0.9814 - val_loss: 3.8616 - val_acc: 0.5209\n",
      "Epoch 85/200\n",
      " - 65s - loss: 0.1107 - acc: 0.9652 - val_loss: 4.0099 - val_acc: 0.5104\n",
      "Epoch 86/200\n",
      " - 64s - loss: 0.0771 - acc: 0.9759 - val_loss: 4.3026 - val_acc: 0.4957\n",
      "Epoch 87/200\n",
      " - 65s - loss: 0.0550 - acc: 0.9834 - val_loss: 3.5123 - val_acc: 0.5696\n",
      "Epoch 88/200\n",
      " - 64s - loss: 0.0477 - acc: 0.9863 - val_loss: 2.8062 - val_acc: 0.6374\n",
      "Epoch 89/200\n",
      " - 65s - loss: 0.0309 - acc: 0.9893 - val_loss: 2.4529 - val_acc: 0.6609\n",
      "Epoch 90/200\n",
      " - 64s - loss: 0.0275 - acc: 0.9899 - val_loss: 3.1221 - val_acc: 0.6070\n",
      "Epoch 91/200\n",
      " - 65s - loss: 0.0483 - acc: 0.9837 - val_loss: 3.8586 - val_acc: 0.4913\n",
      "Epoch 92/200\n",
      " - 64s - loss: 0.1685 - acc: 0.9489 - val_loss: 5.7440 - val_acc: 0.4017\n",
      "Epoch 93/200\n",
      " - 65s - loss: 0.0680 - acc: 0.9784 - val_loss: 3.3763 - val_acc: 0.5748\n",
      "Epoch 94/200\n",
      " - 65s - loss: 0.0353 - acc: 0.9896 - val_loss: 3.1833 - val_acc: 0.5809\n",
      "Epoch 95/200\n",
      " - 65s - loss: 0.0320 - acc: 0.9898 - val_loss: 2.7632 - val_acc: 0.6130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/200\n",
      " - 65s - loss: 0.0417 - acc: 0.9857 - val_loss: 3.0259 - val_acc: 0.6061\n",
      "Epoch 97/200\n",
      " - 64s - loss: 0.0447 - acc: 0.9856 - val_loss: 3.4512 - val_acc: 0.5861\n",
      "Epoch 98/200\n",
      " - 65s - loss: 0.0637 - acc: 0.9799 - val_loss: 4.8431 - val_acc: 0.4713\n",
      "Epoch 99/200\n",
      " - 65s - loss: 0.0726 - acc: 0.9756 - val_loss: 4.1729 - val_acc: 0.4896\n",
      "Epoch 100/200\n",
      " - 65s - loss: 0.0715 - acc: 0.9763 - val_loss: 5.3468 - val_acc: 0.4261\n",
      "Epoch 101/200\n",
      " - 64s - loss: 0.0528 - acc: 0.9829 - val_loss: 3.0366 - val_acc: 0.6096\n",
      "Epoch 102/200\n",
      " - 64s - loss: 0.0361 - acc: 0.9878 - val_loss: 3.2853 - val_acc: 0.6148\n",
      "Epoch 103/200\n",
      " - 65s - loss: 0.0394 - acc: 0.9866 - val_loss: 3.0878 - val_acc: 0.6009\n",
      "Epoch 104/200\n",
      " - 65s - loss: 0.0321 - acc: 0.9881 - val_loss: 2.4519 - val_acc: 0.6678\n",
      "Epoch 105/200\n",
      " - 65s - loss: 0.0646 - acc: 0.9786 - val_loss: 4.0705 - val_acc: 0.5200\n",
      "Epoch 106/200\n",
      " - 65s - loss: 0.0958 - acc: 0.9692 - val_loss: 4.2232 - val_acc: 0.5122\n",
      "Epoch 107/200\n",
      " - 64s - loss: 0.0462 - acc: 0.9838 - val_loss: 3.0098 - val_acc: 0.6391\n",
      "Epoch 108/200\n",
      " - 65s - loss: 0.0398 - acc: 0.9863 - val_loss: 3.0447 - val_acc: 0.6626\n",
      "Epoch 109/200\n",
      " - 64s - loss: 0.0510 - acc: 0.9822 - val_loss: 3.0977 - val_acc: 0.5904\n",
      "Epoch 110/200\n",
      " - 65s - loss: 0.0424 - acc: 0.9855 - val_loss: 3.7703 - val_acc: 0.5391\n",
      "Epoch 111/200\n",
      " - 64s - loss: 0.0633 - acc: 0.9791 - val_loss: 3.0270 - val_acc: 0.6009\n",
      "Epoch 112/200\n",
      " - 64s - loss: 0.0431 - acc: 0.9845 - val_loss: 3.1487 - val_acc: 0.5948\n",
      "Epoch 113/200\n",
      " - 65s - loss: 0.0329 - acc: 0.9882 - val_loss: 2.3921 - val_acc: 0.6504\n",
      "Epoch 114/200\n",
      " - 64s - loss: 0.0277 - acc: 0.9900 - val_loss: 2.7880 - val_acc: 0.6426\n",
      "Epoch 115/200\n",
      " - 65s - loss: 0.0249 - acc: 0.9894 - val_loss: 3.7944 - val_acc: 0.5765\n",
      "Epoch 116/200\n",
      " - 64s - loss: 0.0849 - acc: 0.9709 - val_loss: 4.3886 - val_acc: 0.5130\n",
      "Epoch 117/200\n",
      " - 65s - loss: 0.0778 - acc: 0.9731 - val_loss: 3.6536 - val_acc: 0.5470\n",
      "Epoch 118/200\n",
      " - 65s - loss: 0.0507 - acc: 0.9831 - val_loss: 3.7390 - val_acc: 0.5348\n",
      "Epoch 119/200\n",
      " - 64s - loss: 0.0393 - acc: 0.9866 - val_loss: 2.7188 - val_acc: 0.6322\n",
      "Epoch 120/200\n",
      " - 65s - loss: 0.0304 - acc: 0.9891 - val_loss: 2.5493 - val_acc: 0.6400\n",
      "Epoch 121/200\n",
      " - 65s - loss: 0.0307 - acc: 0.9883 - val_loss: 3.7838 - val_acc: 0.5165\n",
      "Epoch 122/200\n",
      " - 65s - loss: 0.0370 - acc: 0.9868 - val_loss: 3.0648 - val_acc: 0.6009\n",
      "Epoch 123/200\n",
      " - 65s - loss: 0.0374 - acc: 0.9866 - val_loss: 3.3110 - val_acc: 0.5861\n",
      "Epoch 124/200\n",
      " - 64s - loss: 0.0846 - acc: 0.9722 - val_loss: 3.4411 - val_acc: 0.5530\n",
      "Epoch 125/200\n",
      " - 65s - loss: 0.0774 - acc: 0.9745 - val_loss: 3.8367 - val_acc: 0.5565\n",
      "Epoch 126/200\n",
      " - 64s - loss: 0.0301 - acc: 0.9884 - val_loss: 2.8384 - val_acc: 0.6357\n",
      "Epoch 127/200\n",
      " - 65s - loss: 0.0323 - acc: 0.9885 - val_loss: 2.7374 - val_acc: 0.6383\n",
      "Epoch 128/200\n",
      " - 64s - loss: 0.0217 - acc: 0.9925 - val_loss: 2.2012 - val_acc: 0.6809\n",
      "Epoch 129/200\n",
      " - 64s - loss: 0.0167 - acc: 0.9925 - val_loss: 2.2372 - val_acc: 0.7009\n",
      "Epoch 130/200\n",
      " - 64s - loss: 0.0240 - acc: 0.9891 - val_loss: 2.7928 - val_acc: 0.6226\n",
      "Epoch 131/200\n",
      " - 65s - loss: 0.0613 - acc: 0.9790 - val_loss: 4.9492 - val_acc: 0.4643\n",
      "Epoch 132/200\n",
      " - 65s - loss: 0.1009 - acc: 0.9665 - val_loss: 4.3424 - val_acc: 0.5104\n",
      "Epoch 133/200\n",
      " - 65s - loss: 0.0566 - acc: 0.9804 - val_loss: 3.3793 - val_acc: 0.5783\n",
      "Epoch 134/200\n",
      " - 64s - loss: 0.0296 - acc: 0.9892 - val_loss: 2.8778 - val_acc: 0.6504\n",
      "Epoch 135/200\n",
      " - 65s - loss: 0.0177 - acc: 0.9928 - val_loss: 2.5929 - val_acc: 0.6783\n",
      "Epoch 136/200\n",
      " - 65s - loss: 0.0151 - acc: 0.9932 - val_loss: 2.4504 - val_acc: 0.6896\n",
      "Epoch 137/200\n",
      " - 65s - loss: 0.0151 - acc: 0.9926 - val_loss: 2.1747 - val_acc: 0.7087\n",
      "Epoch 138/200\n",
      " - 64s - loss: 0.0343 - acc: 0.9876 - val_loss: 2.3584 - val_acc: 0.6148\n",
      "Epoch 139/200\n",
      " - 64s - loss: 0.1045 - acc: 0.9670 - val_loss: 4.6494 - val_acc: 0.4391\n",
      "Epoch 140/200\n",
      " - 65s - loss: 0.0622 - acc: 0.9781 - val_loss: 3.0058 - val_acc: 0.6287\n",
      "Epoch 141/200\n",
      " - 65s - loss: 0.0289 - acc: 0.9904 - val_loss: 2.4981 - val_acc: 0.6739\n",
      "Epoch 142/200\n",
      " - 65s - loss: 0.0165 - acc: 0.9931 - val_loss: 2.3503 - val_acc: 0.6974\n",
      "Epoch 143/200\n",
      " - 64s - loss: 0.0130 - acc: 0.9928 - val_loss: 1.9495 - val_acc: 0.7296\n",
      "Epoch 144/200\n",
      " - 65s - loss: 0.0151 - acc: 0.9936 - val_loss: 2.0238 - val_acc: 0.7278\n",
      "Epoch 145/200\n",
      " - 65s - loss: 0.0182 - acc: 0.9920 - val_loss: 3.0319 - val_acc: 0.5913\n",
      "Epoch 146/200\n",
      " - 64s - loss: 0.1544 - acc: 0.9517 - val_loss: 2.9406 - val_acc: 0.6096\n",
      "Epoch 147/200\n",
      " - 64s - loss: 0.0443 - acc: 0.9852 - val_loss: 2.9827 - val_acc: 0.5965\n",
      "Epoch 148/200\n",
      " - 64s - loss: 0.0214 - acc: 0.9916 - val_loss: 2.4140 - val_acc: 0.6739\n",
      "Epoch 149/200\n",
      " - 64s - loss: 0.0171 - acc: 0.9920 - val_loss: 1.9943 - val_acc: 0.7339\n",
      "Epoch 150/200\n",
      " - 65s - loss: 0.0143 - acc: 0.9928 - val_loss: 2.0157 - val_acc: 0.7226\n",
      "Epoch 151/200\n",
      " - 64s - loss: 0.0151 - acc: 0.9920 - val_loss: 2.3389 - val_acc: 0.6870\n",
      "Epoch 152/200\n",
      " - 64s - loss: 0.0686 - acc: 0.9772 - val_loss: 5.5533 - val_acc: 0.4252\n",
      "Epoch 153/200\n",
      " - 64s - loss: 0.0863 - acc: 0.9713 - val_loss: 3.0886 - val_acc: 0.5948\n",
      "Epoch 154/200\n",
      " - 65s - loss: 0.0399 - acc: 0.9855 - val_loss: 2.7511 - val_acc: 0.6504\n",
      "Epoch 155/200\n",
      " - 65s - loss: 0.0248 - acc: 0.9901 - val_loss: 2.9242 - val_acc: 0.6330\n",
      "Epoch 156/200\n",
      " - 65s - loss: 0.0218 - acc: 0.9902 - val_loss: 2.0816 - val_acc: 0.7096\n",
      "Epoch 157/200\n",
      " - 64s - loss: 0.0184 - acc: 0.9920 - val_loss: 2.4468 - val_acc: 0.6713\n",
      "Epoch 158/200\n",
      " - 64s - loss: 0.0291 - acc: 0.9890 - val_loss: 2.6028 - val_acc: 0.6313\n",
      "Epoch 159/200\n",
      " - 65s - loss: 0.0699 - acc: 0.9771 - val_loss: 5.7490 - val_acc: 0.4113\n",
      "Epoch 160/200\n",
      " - 65s - loss: 0.0572 - acc: 0.9802 - val_loss: 2.9055 - val_acc: 0.6243\n",
      "Epoch 161/200\n",
      " - 64s - loss: 0.0322 - acc: 0.9875 - val_loss: 2.6838 - val_acc: 0.6443\n",
      "Epoch 162/200\n"
     ]
    }
   ],
   "source": [
    "fit_result = model.fit(\n",
    "    x=X_train,\n",
    "    y=Y_train,\n",
    "    epochs=EPOCHS,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    verbose=2,\n",
    "    callbacks=[callbacks]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LossとAccuracyのグラフを表示する\n",
    "（参考）[MNISTでハイパーパラメータをいじってloss/accuracyグラフを見てみる](https://qiita.com/hiroyuki827/items/213146d551a6e2227810)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, (axL, axR) = plt.subplots(ncols=2, figsize=(16,5))\n",
    "\n",
    "# loss\n",
    "def plot_history_loss(fit):\n",
    "    # Plot the loss in the history\n",
    "    axL.plot(fit.history['loss'],label=\"loss for training\")\n",
    "    axL.plot(fit.history['val_loss'],label=\"loss for validation\")\n",
    "    axL.set_title('model loss')\n",
    "    axL.set_xlabel('epoch')\n",
    "    axL.set_ylabel('loss')\n",
    "    axL.legend(loc='upper right')\n",
    "\n",
    "# acc\n",
    "def plot_history_acc(fit):\n",
    "    # Plot the loss in the history\n",
    "    axR.plot(fit.history['acc'],label=\"accuracy for training\")\n",
    "    axR.plot(fit.history['val_acc'],label=\"accuracy for validation\")\n",
    "    axR.set_title('model accuracy')\n",
    "    axR.set_xlabel('epoch')\n",
    "    axR.set_ylabel('accuracy')\n",
    "    axR.legend(loc='upper right')\n",
    "\n",
    "plot_history_loss(fit_result)\n",
    "plot_history_acc(fit_result)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "周期的に精度が下がる原因を調査する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テストデータで精度を確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = model.evaluate(\n",
    "    x=X_test,\n",
    "    y=Y_test\n",
    ")\n",
    "print('loss for test:', test_result[0])\n",
    "print('accuracy for test:', test_result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 今回学習したモデルを保存する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('keyakizaka_member_detection_mobilenetv2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
